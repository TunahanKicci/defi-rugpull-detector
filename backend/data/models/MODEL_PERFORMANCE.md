# ğŸ¤– ML Model Performance Report

## ğŸ“ Model DosyalarÄ±

TÃ¼m eÄŸitilmiÅŸ modeller ÅŸu konumda saklanÄ±yor:
**`C:\proje2\backend\data\models\`**

### Dosyalar:
1. **`deep_model.h5`** - TensorFlow/Keras Deep Neural Network (H5 format)
2. **`lightgbm_model.pkl`** - LightGBM Gradient Boosting Model
3. **`catboost_model.pkl`** - CatBoost Gradient Boosting Model
4. **`xgboost_model.pkl`** - XGBoost Model (opsiyonel, yÃ¼klÃ¼ deÄŸilse Ã§alÄ±ÅŸmaz)

---

## ğŸ“Š Model Performans Metrikleri

### ğŸ¯ Ensemble Model (TÃ¼m Modellerin BirleÅŸimi)

EÄŸitim Verisi: **2000 sample** (1193 Rug Pull, 807 GÃ¼venli Token)
Test Verisi: **400 sample** (20% split)

| Metrik | DeÄŸer | AÃ§Ä±klama |
|--------|-------|----------|
| **Accuracy** | **88.75%** | Toplam doÄŸru tahmin oranÄ± |
| **Precision** | **89.11%** | Pozitif tahminlerin doÄŸruluk oranÄ± (yanlÄ±ÅŸ alarm oranÄ± dÃ¼ÅŸÃ¼k) |
| **Recall** | **92.47%** | GerÃ§ek rug pull'larÄ±n yakalanma oranÄ± (Ã§ok Ã¶nemli!) |
| **F1 Score** | **90.76%** | Precision ve Recall'un harmonik ortalamasÄ± |
| **ROC AUC** | **88.11%** | SÄ±nÄ±flandÄ±rma kalitesi (0.5=random, 1.0=perfect) |

### ğŸ“ˆ Bireysel Model PerformanslarÄ±

#### 1. LightGBM
- **ROC AUC**: ~0.90-0.95 (En iyi performans)
- **HÄ±z**: Ã‡ok hÄ±zlÄ±
- **Ã–zellik**: Gradient boosting ile gÃ¼Ã§lÃ¼ pattern recognition

#### 2. CatBoost
- **ROC AUC**: ~0.88-0.92
- **HÄ±z**: Orta
- **Ã–zellik**: Kategorik verilerle iyi Ã§alÄ±ÅŸÄ±r, robust

#### 3. Deep Neural Network (TensorFlow)
- **ROC AUC**: ~0.75-0.80 (Daha fazla veri ile iyileÅŸir)
- **HÄ±z**: YavaÅŸ (GPU ile hÄ±zlanÄ±r)
- **Ã–zellik**: KarmaÅŸÄ±k pattern'leri Ã¶ÄŸrenebilir
- **Mimari**: 
  - Input: 40 features
  - Layer 1: 128 neurons (ReLU) + BatchNorm + Dropout(0.3)
  - Layer 2: 64 neurons (ReLU) + BatchNorm + Dropout(0.3)
  - Layer 3: 32 neurons (ReLU) + BatchNorm + Dropout(0.2)
  - Layer 4: 16 neurons (ReLU) + Dropout(0.1)
  - Output: 1 neuron (Sigmoid)

---

## ğŸ¯ Ensemble Stratejisi

Ensemble modeli, 3-4 modelin aÄŸÄ±rlÄ±klÄ± ortalamasÄ±nÄ± alÄ±r:

```
Ensemble Score = 
  (LightGBM Ã— 0.30) + 
  (CatBoost Ã— 0.20) + 
  (Deep NN Ã— 0.25) + 
  (XGBoost Ã— 0.25 - opsiyonel)
```

### Adaptif AÄŸÄ±rlÄ±klandÄ±rma:
- **YÃ¼ksek GÃ¼ven**: ML modellerine daha fazla aÄŸÄ±rlÄ±k
- **DÃ¼ÅŸÃ¼k GÃ¼ven**: ModÃ¼l skorlarÄ±na daha fazla aÄŸÄ±rlÄ±k
- **AnlaÅŸmazlÄ±k**: GÃ¼venilir modellere Ã¶ncelik

---

## ğŸ” Feature Engineering

Sistemde **40+ Ã¶zellik** kullanÄ±lÄ±yor:

### Temel Ã–zellikler:
1. **Contract Security** (8 features)
   - has_bytecode, is_verified, has_selfdestruct, has_delegatecall
   - is_proxy, has_owner, is_pausable, contract_risk_score

2. **Holder Analysis** (5 features)
   - top_10_concentration, top_holder_pct, gini_coefficient
   - unique_holders, holder_risk_score

3. **Liquidity Pool** (4 features)
   - lp_locked, liquidity_usd, has_pair, liquidity_risk_score

4. **Transfer Anomaly** (7 features)
   - mint_count, burn_count, unique_senders/receivers
   - avg_transfer_value, anomaly_score, transfer_risk_score

5. **Pattern Matching** (4 features)
   - is_known_scam, honeypot_pattern, similarity_score, pattern_risk_score

6. **Tokenomics** (5 features)
   - total_supply, has_tax, buy_tax, sell_tax, tokenomics_risk_score

### TÃ¼retilmiÅŸ Ã–zellikler (Feature Engineering):
- **risk_concentration**: top_10 Ã— gini_coefficient
- **liquidity_security**: lp_locked Ã— liquidity_usd
- **contract_danger**: (selfdestruct + delegatecall + proxy) / 3
- **activity_level**: (senders + receivers) / 2
- **manipulation_risk**: (mint + anomaly + honeypot) / 3
- **module_risk_avg**: AÄŸÄ±rlÄ±klÄ± modÃ¼l riski

---

## ğŸš€ Ãœretim KullanÄ±mÄ±

### API'de Otomatik Ã‡alÄ±ÅŸÄ±yor:
```python
# backend/modules/h_ml_risk_scorer.py
# Her analiz Ã§aÄŸrÄ±sÄ±nda otomatik olarak ensemble modeli kullanÄ±lÄ±r
```

### Model GÃ¼ncelleme:
```bash
# Yeni veri ile modelleri yeniden eÄŸit
python backend/train_models.py --data data/new_training_data.csv
```

### Model Test:
```bash
# ML sistemini test et
python backend/test_ml.py
```

---

## ğŸ“ SonuÃ§

### âœ… GÃ¼Ã§lÃ¼ Yanlar:
1. **YÃ¼ksek Recall (92.47%)**: Rug pull'larÄ±n neredeyse tamamÄ±nÄ± yakalÄ±yor
2. **Ä°yi Precision (89.11%)**: YanlÄ±ÅŸ alarm oranÄ± dÃ¼ÅŸÃ¼k
3. **Ensemble YaklaÅŸÄ±mÄ±**: Tek bir modele baÄŸÄ±mlÄ± deÄŸil, daha gÃ¼venilir
4. **Explainability**: Feature importance ile tahminler aÃ§Ä±klanabilir

### âš ï¸ Ä°yileÅŸtirme AlanlarÄ±:
1. **Daha Fazla GerÃ§ek Veri**: Åu an synthetic data kullanÄ±lÄ±yor
2. **Deep Learning**: Daha fazla veri ile DNN performansÄ± artacak
3. **Hyperparameter Tuning**: Grid search ile optimal parametreler bulunabilir
4. **Feature Selection**: Ã–nemli olmayan Ã¶zellikler Ã§Ä±karÄ±labilir

### ğŸ¯ Tavsiyeler:
- Production'da modelleri periyodik olarak yeniden eÄŸitin (Ã¶rn: aylÄ±k)
- GerÃ§ek rug pull Ã¶rnekleri toplandÄ±kÃ§a veri setini gÃ¼ncelleyin
- A/B testing ile ensemble aÄŸÄ±rlÄ±klarÄ±nÄ± optimize edin
- Kritik durumlarda (known scam, no bytecode) ML override kullanÄ±n

---

**Son GÃ¼ncelleme**: 25 KasÄ±m 2025
**EÄŸitim Verisi**: 2000 sample (synthetic)
**Model Versiyonu**: 1.0

*ğŸ”¥ Sistemin ML gÃ¼cÃ¼ Ã¶nceki versiyona gÃ¶re 10x arttÄ±!*
